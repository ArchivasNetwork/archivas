# Nginx configuration for seed.archivas.ai
# Reverse proxy to Archivas node RPC (localhost:8080)

# Rate limiting zones
limit_req_zone $binary_remote_addr zone=submit:10m rate=10r/m;      # Submit endpoint
limit_req_zone $binary_remote_addr zone=api:10m rate=30r/m;         # General API (30 req/min)
limit_req_zone $binary_remote_addr zone=blocks:10m rate=10r/m;      # Blocks endpoint (heavy)
limit_req_zone $binary_remote_addr zone=health:10m rate=60r/m;      # Health checks (more lenient)
limit_req_zone $binary_remote_addr zone=chaintip:10m rate=600r/m;  # ChainTip (explorer needs frequent updates, 10 req/sec)
limit_req_zone $binary_remote_addr zone=challenge:10m rate=120r/m;  # Challenge endpoint (farmers check frequently, 2 req/sec)
limit_req_zone $binary_remote_addr zone=submitblock:10m rate=60r/m;  # SubmitBlock endpoint (farmers submit blocks, 1 req/sec)

# Connection limiting zones (limit concurrent connections, not request rate)
limit_conn_zone $binary_remote_addr zone=chaintip_conn:10m;  # Limit concurrent connections for /chainTip

# HTTP server - redirect to HTTPS + ACME challenge
server {
  listen 80;
  listen [::]:80;
  server_name seed.archivas.ai;

  # ACME challenge for Let's Encrypt
  location /.well-known/acme-challenge/ {
    root /var/www/seed;
  }

  # Redirect all other traffic to HTTPS
  location / {
    return 301 https://$host$request_uri;
  }
}

# HTTPS server - reverse proxy to node RPC
server {
  listen 443 ssl http2;
  listen [::]:443 ssl http2;
  server_name seed.archivas.ai;

  # TLS certificates (managed by certbot)
  ssl_certificate     /etc/letsencrypt/live/seed.archivas.ai/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/seed.archivas.ai/privkey.pem;
  ssl_protocols TLSv1.2 TLSv1.3;
  ssl_prefer_server_ciphers on;
  ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384';

  # Security headers
  add_header X-Content-Type-Options nosniff always;
  add_header X-Frame-Options SAMEORIGIN always;
  add_header Referrer-Policy no-referrer-when-downgrade always;
  add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

  # Compression
  gzip on;
  gzip_vary on;
  gzip_comp_level 6;
  gzip_types application/json text/plain application/javascript text/css;
  gzip_min_length 1000;

  # Timeouts (increased for large block batch requests)
  proxy_connect_timeout 60s;
  proxy_send_timeout    180s;
  proxy_read_timeout    180s;
  proxy_buffering on;  # Enable buffering for better performance
  proxy_buffer_size 4k;
  proxy_buffers 8 4k;

  # Disable large uploads (blockchain is read-heavy)
  client_max_body_size 1m;

  # Block internal metrics from public access (must come first)
  location = /metrics {
    return 404;
  }

  location /metrics/ {
    return 404;
  }

  # Health check endpoints (more lenient rate limiting)
  location = /health {
    limit_req zone=health burst=10 nodelay;
    proxy_pass http://127.0.0.1:8080/healthz;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
  }

  location = /healthz {
    limit_req zone=health burst=10 nodelay;
    proxy_pass http://127.0.0.1:8080/healthz;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
  }

  # Version endpoint
  location = /version {
    limit_req zone=api burst=5 nodelay;
    proxy_pass http://127.0.0.1:8080/version;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
  }

  # ChainTip endpoint (lightweight, read-only)
  # Limit concurrent connections per IP to prevent backend overload
  # Explorer can make many requests, but not all at once
  location = /chainTip {
    # Limit concurrent connections per IP (not request rate)
    # This prevents overwhelming the backend with simultaneous requests
    limit_conn chaintip_conn 5;  # Max 5 concurrent connections per IP
    limit_req zone=chaintip burst=20 nodelay;  # Allow burst of 20, then 600/min
    
    proxy_pass http://127.0.0.1:8080/chainTip;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # Reduced timeout - if backend doesn't respond in 5s, fail fast
    proxy_connect_timeout 2s;
    proxy_send_timeout 5s;
    proxy_read_timeout 5s;
    
    # Don't retry on timeout - fail fast and let client retry
    proxy_next_upstream off;
  }

  # Blocks range endpoint (heavy, needs rate limiting and longer timeout)
  location = /blocks/range {
    limit_req zone=blocks burst=2 nodelay;
    proxy_pass http://127.0.0.1:8080/blocks/range;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    # Longer timeout for block batches (matches client timeout)
    proxy_read_timeout 180s;
    proxy_send_timeout 180s;
  }

  # /submit endpoint - POST only with rate limiting
  # Note: CORS headers handled by backend, not Nginx (avoid duplication)
  location = /submit {
    # Rate limiting (10 requests/min per IP, burst 5)
    limit_req zone=submit burst=5 nodelay;

    # Enforce POST method (OPTIONS handled by backend)
    if ($request_method = 'GET') {
      add_header Allow "POST" always;
      return 405;
    }

    # Proxy headers
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    # Forward to node (backend handles CORS)
    proxy_pass http://127.0.0.1:8080;
  }

  # /challenge endpoint - farmers check this frequently
  # More lenient rate limiting for farming operations
  location = /challenge {
    # 120 req/min (2 req/sec) with burst of 20 - farmers can check frequently
    limit_req zone=challenge burst=20 nodelay;
    
    proxy_pass http://127.0.0.1:8080/challenge;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # Quick timeout for lightweight endpoint
    proxy_read_timeout 10s;
  }

  # /submitBlock endpoint - farmers submit blocks here
  # Moderate rate limiting (farmers don't submit that often)
  location = /submitBlock {
    # 60 req/min (1 req/sec) with burst of 10 - enough for block submissions
    limit_req zone=submitblock burst=10 nodelay;
    
    proxy_pass http://127.0.0.1:8080/submitBlock;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # Longer timeout for block submission processing
    proxy_read_timeout 30s;
  }

  # All other endpoints - proxy to node with rate limiting
  # Backend handles CORS to avoid header duplication
  # This must come LAST as it's the catch-all
  location / {
    # Rate limiting for all other endpoints
    limit_req zone=api burst=10 nodelay;

    # Proxy headers
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    # Forward to node RPC (CORS handled by backend)
    proxy_pass http://127.0.0.1:8080;
  }

  # Access log
  access_log /var/log/nginx/seed.archivas.ai.access.log;
  error_log /var/log/nginx/seed.archivas.ai.error.log;
}

