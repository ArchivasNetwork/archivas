# Nginx configuration for seed.archivas.ai
# Reverse proxy to Archivas node RPC (localhost:8080)

# Rate limiting zones
limit_req_zone $binary_remote_addr zone=submit:10m rate=10r/m;      # Submit endpoint
limit_req_zone $binary_remote_addr zone=api:10m rate=30r/m;         # General API (30 req/min)
limit_req_zone $binary_remote_addr zone=blocks:10m rate=10r/m;      # Blocks endpoint (heavy)
limit_req_zone $binary_remote_addr zone=health:10m rate=60r/m;      # Health checks (more lenient)
limit_req_zone $binary_remote_addr zone=challenge:10m rate=300r/m;  # Challenge endpoint (farmers check frequently, 5 req/sec, backend cached)
limit_req_zone $binary_remote_addr zone=submitblock:10m rate=60r/m;  # SubmitBlock endpoint (farmers submit blocks, 1 req/sec)

# Note: /chainTip has no rate limiting - backend caching handles all load efficiently

# HTTP server - redirect to HTTPS + ACME challenge
server {
  listen 80;
  listen [::]:80;
  server_name seed.archivas.ai;

  # ACME challenge for Let's Encrypt
  location /.well-known/acme-challenge/ {
    root /var/www/seed;
  }

  # Redirect all other traffic to HTTPS
  location / {
    return 301 https://$host$request_uri;
  }
}

# HTTPS server - reverse proxy to node RPC
server {
  listen 443 ssl http2;
  listen [::]:443 ssl http2;
  server_name seed.archivas.ai;

  # TLS certificates (managed by certbot)
  ssl_certificate     /etc/letsencrypt/live/seed.archivas.ai/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/seed.archivas.ai/privkey.pem;
  ssl_protocols TLSv1.2 TLSv1.3;
  ssl_prefer_server_ciphers on;
  ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384';

  # Security headers
  add_header X-Content-Type-Options nosniff always;
  add_header X-Frame-Options SAMEORIGIN always;
  add_header Referrer-Policy no-referrer-when-downgrade always;
  add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

  # Compression
  gzip on;
  gzip_vary on;
  gzip_comp_level 6;
  gzip_types application/json text/plain application/javascript text/css;
  gzip_min_length 1000;

  # Timeouts (increased for large block batch requests)
  proxy_connect_timeout 60s;
  proxy_send_timeout    180s;
  proxy_read_timeout    180s;
  proxy_buffering on;  # Enable buffering for better performance
  proxy_buffer_size 4k;
  proxy_buffers 8 4k;

  # Disable large uploads (blockchain is read-heavy)
  client_max_body_size 1m;

  # Block internal metrics from public access (must come first)
  location = /metrics {
    return 404;
  }

  location /metrics/ {
    return 404;
  }

  # Health check endpoints (more lenient rate limiting)
  location = /health {
    limit_req zone=health burst=10 nodelay;
    proxy_pass http://127.0.0.1:8080/healthz;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
  }

  location = /healthz {
    limit_req zone=health burst=10 nodelay;
    proxy_pass http://127.0.0.1:8080/healthz;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
  }

  # Version endpoint
  location = /version {
    limit_req zone=api burst=5 nodelay;
    proxy_pass http://127.0.0.1:8080/version;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
  }

  # ChainTip endpoint (lightweight, read-only)
  # Backend uses caching - can handle unlimited request rates safely
  # Response time is <5ms, only 1 backend call per second
  # No rate limiting needed - backend caching eliminates load concerns
  location = /chainTip {
    # No rate limiting - backend caching handles all load
    # Explorer can poll as frequently as needed
    
    proxy_pass http://127.0.0.1:8080/chainTip;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # Reasonable timeouts - backend should respond quickly for this endpoint
    proxy_connect_timeout 10s;
    proxy_send_timeout 15s;
    proxy_read_timeout 15s;
    
    # Don't retry on failure - let client handle retries
    proxy_next_upstream off;
    
    # Add CORS headers if needed (backend should handle this, but just in case)
    add_header Access-Control-Allow-Origin * always;
    add_header Access-Control-Allow-Methods "GET, OPTIONS" always;
  }

  # Blocks range endpoint (heavy, needs rate limiting and longer timeout)
  location = /blocks/range {
    limit_req zone=blocks burst=2 nodelay;
    proxy_pass http://127.0.0.1:8080/blocks/range;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    # Longer timeout for block batches (matches client timeout)
    proxy_read_timeout 180s;
    proxy_send_timeout 180s;
  }

  # /submit endpoint - POST only with rate limiting
  # Note: CORS headers handled by backend, not Nginx (avoid duplication)
  location = /submit {
    # Rate limiting (10 requests/min per IP, burst 5)
    limit_req zone=submit burst=5 nodelay;

    # Enforce POST method (OPTIONS handled by backend)
    if ($request_method = 'GET') {
      add_header Allow "POST" always;
      return 405;
    }

    # Proxy headers
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    # Forward to node (backend handles CORS)
    proxy_pass http://127.0.0.1:8080;
  }

  # /challenge endpoint - farmers check this frequently
  # Backend uses caching - can handle high request rates safely
  # Response time is <5ms, only 1 backend call per second
  location = /challenge {
    # Increased rate limit: 300 req/min (5 req/sec) with burst of 50
    # Backend caching eliminates load concerns, farmers can check frequently
    limit_req zone=challenge burst=50 nodelay;
    
    proxy_pass http://127.0.0.1:8080/challenge;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # Quick timeout for lightweight endpoint (with caching, should respond in <100ms)
    proxy_connect_timeout 5s;
    proxy_send_timeout 10s;
    proxy_read_timeout 10s;
    
    # Don't retry on failure - let client handle retries
    proxy_next_upstream off;
  }

  # /submitBlock endpoint - farmers submit blocks here
  # Moderate rate limiting (farmers don't submit that often)
  location = /submitBlock {
    # 60 req/min (1 req/sec) with burst of 10 - enough for block submissions
    limit_req zone=submitblock burst=10 nodelay;
    
    proxy_pass http://127.0.0.1:8080/submitBlock;
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # Longer timeout for block submission processing (can take 60+ seconds)
    proxy_read_timeout 120s;
    proxy_send_timeout 120s;
  }

  # All other endpoints - proxy to node with rate limiting
  # Backend handles CORS to avoid header duplication
  # This must come LAST as it's the catch-all
  location / {
    # Rate limiting for all other endpoints
    limit_req zone=api burst=10 nodelay;

    # Proxy headers
    proxy_set_header Host              $host;
    proxy_set_header X-Real-IP         $remote_addr;
    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    # Forward to node RPC (CORS handled by backend)
    proxy_pass http://127.0.0.1:8080;
  }

  # Access log
  access_log /var/log/nginx/seed.archivas.ai.access.log;
  error_log /var/log/nginx/seed.archivas.ai.error.log;
}

